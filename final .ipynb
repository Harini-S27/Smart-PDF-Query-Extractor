{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5912b97-63d2-4c3f-8c11-4bd833c98dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define functions for PDF processing and query handling\n",
    "# Include your functions for extracting text, preprocessing, and finding relevant passages here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ee0495-ff08-4f91-a6b4-58eb10e26b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_pages(pdf_file):\n",
    "    text = []\n",
    "    page_numbers = []\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_file, \"rb\") as f:\n",
    "            pdf = PyPDF2.PdfReader(f)\n",
    "            total_pages = len(pdf.pages)\n",
    "            \n",
    "            for page_num in range(total_pages):\n",
    "                page = pdf.pages[page_num]\n",
    "                text.append(page.extract_text())\n",
    "                page_numbers.append(page_num + 1)  # Page numbers start from 1\n",
    "                if (page_num + 1) % 10 == 0:\n",
    "                    logging.info(f\"Processed {page_num + 1} pages out of {total_pages}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nText extraction interrupted by user.\")\n",
    "        return [], []\n",
    "    \n",
    "    except PyPDF2.utils.PdfReadError as e:\n",
    "        logging.error(f\"PDF Read Error: {str(e)}\")\n",
    "        return [], []\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text: {str(e)}\")\n",
    "        return [], []\n",
    "    \n",
    "    return text, page_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21498641-1808-4074-8d7a-9c1ae52eacc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processed 10 pages out of 22\n",
      "INFO:root:Processed 20 pages out of 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: DEFINE PROTOTYPING AND LIST OUT THE TYPES OF PROTOTYPING\n",
      "\n",
      "Page 1: OOASE IMP QUES  \n",
      "UNIT 1  \n",
      "2M \n",
      "1.DEFINE SW DEVELOPMENT LIFE CYCLE(SDLC)  \n",
      "• Process in se is not a single step process.it includes steps/stages in software  development.  \n",
      "These are:  \n",
      "a. Requirement process or feasibility study  \n",
      "b. Design process or requirement analysis and specification  \n",
      "c. Coding process or coding and unit testing  \n",
      "d. Testing process or integration and system testing  \n",
      "e. Maintenance process or maintenance and support  \n",
      " \n",
      "2. DEFINE PROTOTYPING AND LIST OUT THE TYPES OF PROTOTYPING  \n",
      "• A prototype is a version of a software product developed in the early stages of the product's \n",
      "life cycle for specific, experimental purposes.  \n",
      "• A Prototype enables you to fully understand how easy or difficult it will be to implement \n",
      "some of the features of the system.  \n",
      "• The main idea here is to build a prototype with uses -case modeling to design systems that \n",
      "users like and need.  \n",
      "TYPES:  \n",
      " \n",
      "• A horizontal prototype is a simulation of the interface. but contains no functionality  and it is \n",
      "quick to implement, providing a good overall feel of the system . \n",
      "• A vertical prototype is a subset of the system features with complete functionality  and can \n",
      "be tested in great depth.  \n",
      "• An analysis prototype is an aid for exploring the problem domain. This class of prototype is \n",
      "used to inform the user and demonstrate the proof of a concept.  \n",
      "• A domain prototype is an aid for the incremental development of the ultimate software \n",
      "solution. It often is used as a tool for the staged delivery of subsystems . \n",
      " \n",
      "3.COMPARE VERIFICATION AND VALIDATION  \n",
      "VERIFICATION  VALIDATION  \n",
      " \n",
      "It includes checking documents, design, codes \n",
      "and programs.  It includes testing and validating the actual \n",
      "product.  \n",
      "Verification is the static testing.  Validation is the dynamic testing.  \n",
      "It does  not include the execution of the code.  It includes the execution of the code.  \n",
      "The goal of verification is application and \n",
      "software architecture and specification.  \n",
      " The goal of validation is an actual product.  \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # Configure logging level\n",
    "\n",
    "# Function to extract text and page numbers from PDF using PdfReader\n",
    "def extract_text_and_pages(pdf_file):\n",
    "    text = []\n",
    "    page_numbers = []\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_file, \"rb\") as f:\n",
    "            pdf = PyPDF2.PdfReader(f)\n",
    "            total_pages = len(pdf.pages)\n",
    "            \n",
    "            for page_num in range(total_pages):\n",
    "                page = pdf.pages[page_num]\n",
    "                text.append(page.extract_text())\n",
    "                page_numbers.append(page_num + 1)  # Page numbers start from 1\n",
    "                if (page_num + 1) % 10 == 0:\n",
    "                    logging.info(f\"Processed {page_num + 1} pages out of {total_pages}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        # Handle keyboard interrupt (Ctrl+C)\n",
    "        logging.info(\"\\nText extraction interrupted by user.\")\n",
    "        return [], []  # Return empty lists to handle interrupted extraction\n",
    "        \n",
    "    except PyPDF2.utils.PdfReadError as e:\n",
    "        logging.error(f\"PDF Read Error: {str(e)}\")\n",
    "        return [], []  # Return empty lists if there's a specific PDF read error\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text: {str(e)}\")\n",
    "        return [], []  # Return empty lists for other unexpected errors\n",
    "    \n",
    "    return text, page_numbers\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, convert to lowercase, and tokenize\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "# Function to find relevant passages using TF-IDF and cosine similarity\n",
    "def find_relevant_passages(query, text, page_numbers):\n",
    "    # Preprocess query\n",
    "    query_tokens = preprocess_text(query)\n",
    "    \n",
    "    # Preprocess and tokenize text\n",
    "    preprocessed_text = [preprocess_text(doc) for doc in text]\n",
    "    \n",
    "    # Initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([' '.join(doc) for doc in preprocessed_text])\n",
    "    \n",
    "    # Vectorize query\n",
    "    query_vec = vectorizer.transform([' '.join(query_tokens)])\n",
    "    \n",
    "    # Calculate cosine similarities between query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Sort documents by similarity score (descending)\n",
    "    sorted_indices = cosine_similarities.argsort()[::-1]\n",
    "    \n",
    "    # Collect relevant passages and page numbers\n",
    "    relevant_passages = []\n",
    "    for i in sorted_indices:\n",
    "        if cosine_similarities[i] > 0.2:  # Adjust similarity threshold as needed\n",
    "            relevant_passages.append((text[i], page_numbers[i]))\n",
    "    \n",
    "    return relevant_passages\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "uploaded_pdf =  r\"C:\\Users\\91984\\Downloads\\OOASE IMP QUES (1).pdf\"  # Replace with your file path\n",
    "query = \"DEFINE PROTOTYPING AND LIST OUT THE TYPES OF PROTOTYPING\"\n",
    "\n",
    "# Extract text and page numbers from PDF\n",
    "text, page_numbers = extract_text_and_pages(uploaded_pdf)\n",
    "\n",
    "# Check if text extraction was interrupted or encountered an error\n",
    "if not text:\n",
    "    print(\"Text extraction was interrupted or encountered an error. Please check the logs for details.\")\n",
    "else:\n",
    "    # Find relevant passages for the query\n",
    "    relevant_passages = find_relevant_passages(query, text, page_numbers)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    if not relevant_passages:\n",
    "        print(\"No relevant passages found.\")\n",
    "    else:\n",
    "        for passage, page_number in relevant_passages:\n",
    "            print(f\"Page {page_number}: {passage}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31cad04-b2cf-469f-8306-f1828d47a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processed 10 pages out of 22\n",
      "INFO:root:Processed 20 pages out of 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SINGLE INHERITANCE\n",
      "\n",
      "Page 7: b) SINGLE AND MULTIPLE INHERITANCE  \n",
      "SINGLE INHERITANCE  \n",
      "DEFINITION  \n",
      "A derived class inherits the properties and behaviors of a single base class. In other words, it \n",
      "allows a derived class to inherit the characteristics of exactly one base class.  \n",
      "PROGRAM  \n",
      "#include <iostream>  \n",
      "using namespace std;  \n",
      "class Base  \n",
      "{public:  \n",
      "int cal()  \n",
      "{int a=5,b=5;  \n",
      "return a+b;}};  \n",
      "class Derived: public Base  \n",
      "{public:  \n",
      "void disp()  \n",
      "{cout << cal();}};  \n",
      "int main()  \n",
      "{Derived d;  \n",
      "d.disp();  \n",
      "return 0;}  \n",
      " \n",
      "OUTPUT  \n",
      "10 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)  # Configure logging level\n",
    "\n",
    "# Function to extract text and page numbers from PDF using PdfReader\n",
    "def extract_text_and_pages(pdf_file):\n",
    "    text = []\n",
    "    page_numbers = []\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_file, \"rb\") as f:\n",
    "            pdf = PyPDF2.PdfReader(f)\n",
    "            total_pages = len(pdf.pages)\n",
    "            \n",
    "            for page_num in range(total_pages):\n",
    "                page = pdf.pages[page_num]\n",
    "                text.append(page.extract_text())\n",
    "                page_numbers.append(page_num + 1)  # Page numbers start from 1\n",
    "                if (page_num + 1) % 10 == 0:\n",
    "                    logging.info(f\"Processed {page_num + 1} pages out of {total_pages}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        # Handle keyboard interrupt (Ctrl+C)\n",
    "        logging.info(\"\\nText extraction interrupted by user.\")\n",
    "        return [], []  # Return empty lists to handle interrupted extraction\n",
    "        \n",
    "    except PyPDF2.utils.PdfReadError as e:\n",
    "        logging.error(f\"PDF Read Error: {str(e)}\")\n",
    "        return [], []  # Return empty lists if there's a specific PDF read error\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text: {str(e)}\")\n",
    "        return [], []  # Return empty lists for other unexpected errors\n",
    "    \n",
    "    return text, page_numbers\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, convert to lowercase, and tokenize\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "# Function to find relevant passages using TF-IDF and cosine similarity\n",
    "def find_relevant_passages(query, text, page_numbers):\n",
    "    # Preprocess query\n",
    "    query_tokens = preprocess_text(query)\n",
    "    \n",
    "    # Preprocess and tokenize text\n",
    "    preprocessed_text = [preprocess_text(doc) for doc in text]\n",
    "    \n",
    "    # Initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([' '.join(doc) for doc in preprocessed_text])\n",
    "    \n",
    "    # Vectorize query\n",
    "    query_vec = vectorizer.transform([' '.join(query_tokens)])\n",
    "    \n",
    "    # Calculate cosine similarities between query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Sort documents by similarity score (descending)\n",
    "    sorted_indices = cosine_similarities.argsort()[::-1]\n",
    "    \n",
    "    # Collect relevant passages and page numbers\n",
    "    relevant_passages = []\n",
    "    for i in sorted_indices:\n",
    "        if cosine_similarities[i] > 0.2:  # Adjust similarity threshold as needed\n",
    "            relevant_passages.append((text[i], page_numbers[i]))\n",
    "    \n",
    "    return relevant_passages\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "uploaded_pdf =  r\"C:\\Users\\91984\\Downloads\\OOASE IMP QUES (1).pdf\"  # Replace with your file path\n",
    "query = \"SINGLE INHERITANCE\"\n",
    "\n",
    "# Extract text and page numbers from PDF\n",
    "text, page_numbers = extract_text_and_pages(uploaded_pdf)\n",
    "\n",
    "# Check if text extraction was interrupted or encountered an error\n",
    "if not text:\n",
    "    print(\"Text extraction was interrupted or encountered an error. Please check the logs for details.\")\n",
    "else:\n",
    "    # Find relevant passages for the query\n",
    "    relevant_passages = find_relevant_passages(query, text, page_numbers)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    if not relevant_passages:\n",
    "        print(\"No relevant passages found.\")\n",
    "    else:\n",
    "        for passage, page_number in relevant_passages:\n",
    "            print(f\"Page {page_number}: {passage}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a09c50-46fd-4116-afa6-aa97dc7f7f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
